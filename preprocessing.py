# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rN-d2vMK5fSaxOE2UMzRp4U3YrJ8Mv-3
"""

import string
import regex as re
def text_preprocess(x):
    x = str(x).lower()
    x = x.replace(",000,000", "m").replace(",000", "k").replace("′", "'").replace("’", "'")\
                           .replace("won't", "will not").replace("cannot", "can not").replace("can't", "can not")\
                           .replace("n't", " not").replace("what's", "what is").replace("it's", "it is")\
                           .replace("'ve", " have").replace("i'm", "i am").replace("'re", " are")\
                           .replace("he's", "he is").replace("she's", "she is").replace("'s", " own")\
                           .replace("%", " percent ").replace("₹", " rupee ").replace("$", " dollar ")\
                           .replace("€", " euro ").replace("'ll", " will") \
                           .replace("subject: ","")\
                           .replace("\n"," ")\
                           .replace("\r"," ")\
                           .replace("#","")\
                           .replace("/","or")

    x = re.sub(r'\([^)]*\)', '', x)
    return x

df["Features"] = df["Features"].apply(lambda x: text_preprocess(x))
df['Features'].str.replace('[{}]'.format(string.punctuation), '')

lst = df.Features.tolist()

import pandas as pd
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

def tokenize_tweet(tweet):
    tokens = word_tokenize(tweet)
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]
    return filtered_tokens


df1['tokenized_tweet'] = df1['review'].apply(tokenize_tweet)

# Sample DataFrame
data = {'sentences': ["This is the first sentence.", "This is the second sentence.", "And this is the third sentence."]}
df = pd.DataFrame(data)

# Step 1: Convert the feature column into a list of sentences
sentence_list = df['sentences'].tolist()

# Step 2: Convert the list of sentences into a single string of sentences
sentence_string = ' '.join(sentence_list)